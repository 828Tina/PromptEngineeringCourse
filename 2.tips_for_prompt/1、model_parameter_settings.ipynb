{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixinyu/miniconda3/envs/prompt/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/lixinyu/miniconda3/envs/prompt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "### 加载模型：Qwen2.5-0.5B-Instruct模型\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name_or_path = '/your/path/of/Qwen2.5-3B-Instruct'  # 替换为你下载的模型路径\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map='auto', torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理函数\n",
    "def inference(model,tokenizer,prompt,system=\"你是一个专业的人工智能助手\",max_new_tokens=512,temperature=0.9):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    # 提取仅由模型生成的token ids（排除输入部分）\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    # 统计生成的tokens数量（直接取生成序列的长度）\n",
    "    generated_tokens_count = len(generated_ids[0])  # 因输入是单条，取第一个元素的长度\n",
    "    # 解码生成的token ids为文本\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 返回响应文本和生成的tokens数量\n",
    "    return {\n",
    "        \"response\":response,\n",
    "        \"generated_tokens_count\":generated_tokens_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659062f7",
   "metadata": {},
   "source": [
    "# 模型参数设置\n",
    "\n",
    "无论是本地模型推理，还是API调用大模型进行交互，你都需要通过配置一些参数以获得不同的提示结果。调整这些设置对于提高响应的可靠性非常重要，你可能需要进行一些实验才能找出适合您的用例的正确设置。以下是使用不同LLM提供程序时会遇到的常见设置：\n",
    "\n",
    "- max length：max length用于指定大模型上下文文本的总长度上限，包括输入文本（prompt）和生成的新文本两部分。但是一般不用这个参数，因为限制为输入和输出总长，如果超过这个范围，会报错，而一般你并不能预测到能生成多少内容，所以一般用max new tokens比较多。\n",
    "- max new tokens：指定生成文本的新生成部分的长度上限，不包括输入文本。\n",
    "> 上面两个参数是通用参数，在[transformers官方代码](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/configuration_utils.py#L104)上，本地推理的时候基本名称不变，但是使用API的时候由于模仿了ChatGPT的API格式，最大生成文本长度限制可能是max_tokens，因此在实际使用的时候需要注意。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '春日里，万物复苏，大地披上了嫩绿的新装，柔和的阳光如同细腻的丝绸轻抚着每一寸土地，空气中弥漫着清新的花香与泥土的气息，仿佛大自然最温柔的呢喃，令人心旷神怡。', 'generated_tokens_count': 55}\n",
      "{'response': '【序章】\\n2165年，距离地球3.5亿公里处，人类的“曙光号”探测飞船正以每秒7.7公里的速度穿越太空，向太阳系的尽头驶去。船内，五名宇航员正坐在自己的位置上，他们的脸上写满了紧张和期待。这不仅仅是一次普通的航天任务，更是人类历史上的里程碑，人类第一次真正意义上踏足火星。\\n“曙光号”飞船内部的宽敞空间与舱壁的银色反射着阳光。舱内的空气循环系统运转良好，舱内温度保持在恒定范围内。', 'generated_tokens_count': 128}\n",
      "{'response': '在遥远的未来，地球已经步入了科技高度发达的时代，人类对宇宙的探索热情也日益高涨。2067年，人类的航天事业取得了前所未有的成就，人类终于实现了首次登陆火星的梦想。这一天，编号为“天问”的大型运输飞船正载着人类第一批火星探测任务的成员——艾米莉亚、迈克尔、莉娜和杰克，向着火星进发。\\n\\n飞船“天问”在发射后，以接近光速的速度冲破大气层，向火星进发。飞船内部，四个宇航员都处在极度紧张的状态中。他们相互鼓励，共同面对即将到来的未知挑战。艾米莉亚坐在操纵台前，双手紧握，专注地看着飞船前方的显示器。她心中充满了激动与不安，因为她知道，一旦错过这个机会，可能永远无法再踏上这颗红色星球。她深知，这不仅是一次探险之旅，更是一次改变人类历史的重要旅程。\\n\\n与此同时，飞船遭遇了技术故障。导航系统出现了一些错误信号，导致飞船偏离了预定航线。面对这样的危机，艾米莉亚冷静地指挥着飞船调整姿态，将它重新调整到正确的轨道。她一边与地面指挥部保持联系，报告情况，一边密切关注着飞船的状态。在她的努力下，飞船最终恢复了正常运行。\\n\\n经过数周的飞行，飞船终于进入了火星轨道，距离火星越来越近。此时，飞船外部的摄像头捕捉到了令人震撼的画面：火星上呈现出一片红尘，仿佛是宇宙中一块巨大的火炭，而火星的天空则是无边无际的深邃夜空，星河璀璨，银河倾泻，美得令人窒息。飞船逐渐降速，进入降落阶段。艾米莉亚站在操纵台上，目不转睛地看着下方的火星地表，心中充满了期待和激动。\\n\\n降落过程中，飞船遇到了一些预料之外的问题。由于火星引力较弱，飞船降落速度过快，导致舱门无法正常开启。艾米莉亚立即采取紧急措施，尝试通过调整姿态来控制降落速度，同时迅速通知地面指挥部。在地面指挥部的帮助下，他们找到了解决方案，舱门终于顺利开启。此时，四名宇航员的心跳加速，呼吸急促。随着舱门缓缓打开，一股刺鼻的空气混合着尘土味扑面而来。他们看到了一片陌生而壮观的景象：广阔的荒漠、起伏的山丘、孤独的沙丘……一切都显得那么新奇又神秘。\\n\\n舱门完全打开后，四个宇航员相继踏上了火星的土壤。他们的脚下软绵绵的，仿佛踩在棉花上，但并不柔软，而是充满沙粒。在火星的重力环境下，每一步都显得异常艰难。火星的表面环境极其恶劣，没有空气，温度极端变化，风速极大，沙尘暴更是时有发生。这些条件使得他们的行动变得更加困难，但他们并没有放弃。在他们的共同努力下，火星上的第一块石头被采集到，标志着人类首次登陆火星的辉煌时刻。\\n\\n在这场冒险中，人类克服了许多困难，也学会了如何与这种极端环境共处。他们采集样本，进行科学研究，还建立了第一个火星基地，为未来的火星殖民奠定了基础。而他们所经历的一切，都将成为人类历史上一段不可磨灭的记忆，激励着后来者不断探索和前行。', 'generated_tokens_count': 698}\n"
     ]
    }
   ],
   "source": [
    "## Qwen推理需要max new tokens\n",
    "## 会尽量在范围内回答，但是如果超出范围，会截断\n",
    "\n",
    "\n",
    "### 在范围内生成\n",
    "max_new_tokens=128\n",
    "prompt=\"\"\"请你写一段简单的描述春天、非常优美的的句子\"\"\"\n",
    "print(inference(model,tokenizer,prompt,max_new_tokens=max_new_tokens))\n",
    "\n",
    "\n",
    "### 生成内容太多，会截断\n",
    "prompt=\"\"\"请写一个科幻故事，详细描述人类首次登陆火星的全过程，从飞船脱离地球轨道开始，包括宇航员的心理活动、遇到的技术问题、火星表面的环境细节，以及登陆成功后的第一小时行动。要求内容至少 800 字，尽量详细，不要省略任何关键步骤。\"\"\"\n",
    "print(inference(model,tokenizer,prompt,max_new_tokens=max_new_tokens))\n",
    "\n",
    "\n",
    "### 扩大最长生成长度，生成更多内容，而且不会截断\n",
    "max_new_tokens=2048\n",
    "prompt=\"\"\"请写一个科幻故事，详细描述人类首次登陆火星的全过程，从飞船脱离地球轨道开始，包括宇航员的心理活动、遇到的技术问题、火星表面的环境细节，以及登陆成功后的第一小时行动。要求内容至少 800 字，尽量详细，不要省略任何关键步骤。\"\"\"\n",
    "print(inference(model,tokenizer,prompt,max_new_tokens=max_new_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8750e9",
   "metadata": {},
   "source": [
    "- temperature：用于控制生成文本的随机性和创造性。它影响模型在预测下一个 token 时对概率分布的处理方式。temperature范围在[0,1]之间，参数值越小，模型就会返回越确定的一个结果。\n",
    "- top_p：也称为核采样，Nucleus Sampling，是一种用于控制生成文本随机性的策略参数，它与之前提到的 temperature 类似，但采用了不同的机制来筛选下一个可能的 token。\n",
    "- top_k：top_k（Top-K 采样） 是一种控制生成文本随机性的策略参数，它通过限制模型在预测下一个 token 时的选择范围，来平衡生成内容的多样性和可靠性。\n",
    "> 一般建议是改变temperature、top_p、top_k其中一个参数就行，不用都调整，因为都是为了控制回答的多样性。\n",
    "\n",
    "- do_sample：用于控制生成过程中是否使用随机采样策略。它是决定 temperature、top_k、top_p 等随机性参数是否生效的开关，默认是False。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ee1d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '当然可以，以下是五种适合周末带孩子外出的活动建议：\\n\\n1. **公园野餐**：选择一个风景优美的公园，带上简单的食物和饮料，享受户外时光。\\n2. **动物园或植物园游览**：这些地方不仅能让孩子近距离接触各种动物和植物，还能增长知识。\\n3. **博物馆参观**：许多城市都有丰富的博物馆资源，可以让孩子了解历史、艺术等多方面的知识。\\n4. **亲子手工制作**：比如做手工艺品或者烘焙蛋糕，既能增进亲子关系，又能培养孩子的动手能力。\\n5. **户外运动**：如骑自行车、徒步旅行或是简单的攀岩体验，既锻炼身体又能让孩子们接触大自然。\\n\\n希望这些建议能帮助到您！', 'generated_tokens_count': 156}\n"
     ]
    }
   ],
   "source": [
    "## 温度参数，如果越低，生成越单调，每次生成的重复性越高；如果越高，生成越多样\n",
    "\n",
    "temperature=0.1\n",
    "prompt=\"\"\"周末要带孩子出去玩，推荐5种不同的活动。回答尽量简单\"\"\"\n",
    "print(inference(model,tokenizer,prompt,temperature=temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c8eeb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4649083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5741d367",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
