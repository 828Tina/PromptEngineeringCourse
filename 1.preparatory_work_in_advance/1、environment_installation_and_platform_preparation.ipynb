{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cb1dc9",
   "metadata": {},
   "source": [
    "# ä¸‹è½½å¤§æ¨¡å‹\n",
    "\n",
    "> é™¤éç‰¹æ®Šè¯´æ˜ï¼Œæ¨¡å‹åŸºæœ¬éƒ½é‡‡ç”¨Qwenæ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œä¼šä½¿ç”¨baseã€instructæˆ–è€…reasoningæ¨¡å‹è¿›è¡Œå¯¹æ¯”å®éªŒã€‚\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„ä»£ç å¯ä»¥å°†å¼€æºæ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œ***å¦‚æœä½¿ç”¨APIæ–¹å¼ï¼Œä¸éœ€è¦ä¸‹è½½åˆ°æœ¬åœ°***\n",
    "\n",
    "ä¸ºå¿«é€Ÿã€é¡ºåˆ©å®‰è£…ï¼Œæˆ‘ä»¬ä½¿ç”¨modelscopeï¼Œä¹Ÿå°±æ˜¯é­”æ­ç¤¾åŒºä¸­çš„æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a818fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model Qwen/Qwen2.5-3B  --local_dir /your/path/of/Qwen2.5-3B  # ä¸‹è½½baseæ¨¡å‹\n",
    "!modelscope download --model Qwen/Qwen2.5-3B-Instruct  --local_dir /your/path/of/Qwen2.5-3B-Instruct  # ä¸‹è½½instructæ¨¡å‹\n",
    "!modelscope download --model Qwen/Qwen3-1.7B  --local_dir /your/path/of/Qwen3-1.7B  # ä¸‹è½½reasoningæ¨¡å‹\n",
    "!modelscope download --model Qwen/Qwen2.5-VL-3B-Instruct  --local_dir /your/path/of/Qwen2.5-VL-3B-Instruct  # ä¸‹è½½VLæ¨¡å‹\n",
    "!modelscope download --model Qwen/Qwen2.5-7B  --local_dir /home/lixinyu/weights/Qwen2.5-7B  # ä¸‹è½½7Bæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd7781",
   "metadata": {},
   "source": [
    "# Huggingface&Modelscope\n",
    "\n",
    "huggingfaceæˆ–è€…modelscopeä¸Šæ¨¡å‹å‘å¸ƒçš„æ—¶å€™ä¸€èˆ¬ä¼šè‡ªå¸¦æ¨ç†ä»£ç ï¼Œæ¯”å¦‚Qwenæ¨¡å‹ï¼Œæ¨ç†ä»£ç åœ¨è¿™ğŸ‘‰[Qwen2.5æ¨ç†ä»£ç ](https://huggingface.co/Qwen/Qwen2.5-3B)ã€‚\n",
    "\n",
    "æˆ‘ä»¬åªéœ€è¦æ ¹æ®è‡ªèº«éœ€è¦ä¿®æ”¹æ¨¡å‹åç§°æˆ–è€…åœ°å€å°±å¯ä»¥å®ç°**æœ¬åœ°**çš„ç®€å•æ¨ç†ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯huggingfaceçš„transformersåº“ï¼Œæ‰€ä»¥éœ€è¦å…ˆå®‰è£…transformersåº“ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce869535",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "### åŠ è½½æ¨¡å‹\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name_or_path = 'Qwen/Qwen2.5-3B'  # å¯ä»¥æ›¿æ¢ä¸ºä½ ä¸‹è½½çš„æ¨¡å‹è·¯å¾„\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map='auto', torch_dtype='auto')\n",
    "\n",
    "### æç¤ºè¯\n",
    "prompt = \"Hello, Who are you?\"\n",
    "\n",
    "### æ¨ç†ä»£ç \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563e1b1",
   "metadata": {},
   "source": [
    "# vllm\n",
    "\n",
    "vLLMæ˜¯ä¸€ä¸ªå¿«é€Ÿä¸”æ˜“äºä½¿ç”¨çš„åº“ï¼Œç”¨äº LLM æ¨ç†å’ŒæœåŠ¡ï¼Œå¯ä»¥å’ŒHuggingFace æ— ç¼é›†æˆã€‚vLLMåˆ©ç”¨äº†å…¨æ–°çš„æ³¨æ„åŠ›ç®—æ³•ã€ŒPagedAttentionã€ï¼Œæœ‰æ•ˆåœ°ç®¡ç†æ³¨æ„åŠ›é”®å’Œå€¼ã€‚\n",
    "\n",
    "`vllmåœ¨ååé‡æ–¹é¢ï¼ŒvLLMçš„æ€§èƒ½æ¯”HuggingFace Transformers(HF)é«˜å‡º24å€ï¼Œæ–‡æœ¬ç”Ÿæˆæ¨ç†ï¼ˆTGIï¼‰é«˜å‡º3.5å€ã€‚`\n",
    "\n",
    "ç®€å•ç‚¹è¯´å°±æ˜¯vllmæ¡†æ¶çš„æ¨ç†é€Ÿåº¦å¾ˆå¿«ï¼Œä½†æ˜¯æ˜¾å­˜å ç”¨è¾ƒé«˜ï¼ŒåŒæ ·çš„3Bæ¨¡å‹ï¼Œæœ¬åœ°æ¨ç†å¯èƒ½åªéœ€è¦15GBå·¦å³ï¼Œè€Œvllmæ¡†æ¶åˆ™éœ€è¦37GBï¼Œå› æ­¤å¦‚æœç¡¬ä»¶èµ„æºä¸è¶³ï¼Œvllmå¹¶ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¯å¢ƒé‡Œå®‰è£…vllmåº“\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd89a6",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬åœ¨ä½¿ç”¨çš„æ—¶å€™ä¸»è¦å‚è€ƒçš„æ˜¯æ¨ç†æ—¶å…¼å®¹OpenAIæ¥å£çš„æƒ…å†µï¼Œè¯¦ç»†å¯ä»¥å‚è€ƒğŸ‘‰[ä¸­æ–‡æ–‡æ¡£](https://vllm.hyper.ai/docs/inference-and-serving/openai_compatible_server/)ã€‚\n",
    "\n",
    "æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤ä¾æ¬¡è¿è¡Œä»£ç \n",
    "\n",
    "1. åœ¨æœ¬åœ°é»˜è®¤ç«¯å£è·‘æœ¬åœ°æ¨¡å‹ï¼Œå¼€å¯ä¸€ä¸ªç»ˆç«¯ï¼Œè¿è¡Œä¸‹é¢çš„ä»£ç \n",
    "    ```bash\n",
    "    vllm serve /your/path/of/model\n",
    "    ```\n",
    "2. å¼€å¯æ–°çš„ç»ˆç«¯é¡µé¢è¿è¡Œå„ä¸ªä»£ç ã€‚åœ¨æ–°çš„ç»ˆç«¯é¡µé¢ï¼Œæˆ‘ä»¬å°±å¯ä»¥è·‘æˆ‘ä»¬å¯¹åº”çš„æœåŠ¡äº†ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤§æ¨¡å‹æ¥è¿›è¡Œæ¨ç†çš„æ—¶å€™å¯ä»¥ä½¿ç”¨[openaiçš„promptçš„APIçš„æ¥å£](https://openai.apifox.cn/api-55352401)æˆ–è€…[messageså¯¹åº”çš„APIæ¥å£](https://openai.apifox.cn/api-67883981)ç­‰ï¼Œè¾“å…¥æ¥å£å‚è€ƒç»™å‡ºçš„æ–‡æ¡£å³å¯\n",
    "\n",
    "    ```bash\n",
    "    python your_code.py\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a65961",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "å¤§æ¨¡å‹çš„ API è°ƒç”¨ï¼Œç®€å•æ¥è¯´ï¼Œæ˜¯æŒ‡å¼€å‘è€…æˆ–ç”¨æˆ·é€šè¿‡åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰ ä¸å¤§æ¨¡å‹è¿›è¡Œäº¤äº’ï¼Œä»è€Œåˆ©ç”¨å¤§æ¨¡å‹çš„èƒ½åŠ›å®Œæˆç‰¹å®šä»»åŠ¡çš„è¿›ç¨‹ï¼Œè¿™äº›å¤§æ¨¡å‹æ— éœ€éƒ¨ç½²åˆ°æœ¬åœ°ï¼Œä½ ä½¿ç”¨çš„èµ„æºå…¶å®æ˜¯è¿™äº›å‚å•†æä¾›çš„æœåŠ¡é›†ç¾¤ï¼Œä¸ä»…æ¨ç†é€Ÿåº¦å¿«ï¼Œè€Œä¸”å¹¶ä¸å ç”¨æ˜¾å­˜ï¼Œä¸è¿‡æ¯ä¸ªæ¨¡å‹ä¼šæœ‰è´¹ç”¨çš„æ¶ˆè€—ï¼Œä¸ä¸€å®šèƒ½å…è´¹ä½¿ç”¨ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¾ˆå¤šèµ„æºï¼Œè¿™é‡Œæˆ‘ä»¬ç®€å•ä¸¾ä¸¤ä¸ªä¾‹å­ï¼Œåˆ†åˆ«æ˜¯ç¡…åŸºæµåŠ¨å’Œé˜¿é‡Œç™¾ç‚¼ï¼Œå¯ä»¥å‚è€ƒä»–ä»¬çš„å®˜ç½‘æ–‡æ¡£ç­‰ï¼š\n",
    "1. ç¡…åŸºæµåŠ¨ï¼š[å®˜ç½‘](https://cloud.siliconflow.cn/sft-d1n0sv33jrms738gmgpg/models)\n",
    "2. é˜¿é‡Œç™¾ç‚¼ï¼š[API](https://bailian.console.aliyun.com/?spm=5176.12818093_47.resourceCenter.1.223c2cc96V9eQn&tab=api#/api/?type=model&url=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2712576.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fdb3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"0197f230c1437d020e874c6bff06fec3\",\"object\":\"chat.completion\",\"created\":1752114971,\"model\":\"Qwen/Qwen3-8B\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":13,\"completion_tokens\":12,\"total_tokens\":25,\"completion_tokens_details\":{\"reasoning_tokens\":0}},\"system_fingerprint\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "api_key=\"sk-\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"Qwen/Qwen3-8B\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ä½ å¥½\"\n",
    "        }\n",
    "    ],\n",
    "    \"enable_thinking\":False\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16122c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "result = json.loads(response.text)\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397dd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
