{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4a61ca",
   "metadata": {},
   "source": [
    "# 多模态提示词\n",
    "多模态模型能够同时理解、处理、生成文字、图像、语音、视频等多种信息，多模态模型大致分为理解型模型和生成类模型，其中理解型模型输入多模态信息，输出是文字类型，而生成类模型输入可以是多模态信息，输出也是多模态类，比如让模型生成一张“阳光下的彩虹”的图像，多模态生成类模型就能够生成精美的图像。\n",
    "\n",
    "简单来说，单模态模型仅有文字，相当于人类仅能对话，看不到图像、听不到声音、说不出话，多模态模型相当于赋予模型人类的五感，它不仅能够去认识我们的这个文字，还能听懂我们的语音，看到我们的图片，理解我们的视频。\n",
    "\n",
    "本节我们将针对多模态模型设计提示词，当输入是由文字、图像、视频、音频等多种模态组成的信息时，如何引导AI生成我们理想的结果。\n",
    "\n",
    "使用的模型为Qwen系列模型，其中图像和视频都由Qwen2.5-vl模型实现。关于推理代码，我们可以从[modelscope官网](https://www.modelscope.cn/models/Qwen/Qwen2.5-VL-7B-Instruct)得知。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4abc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixinyu/miniconda3/envs/prompt/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/lixinyu/miniconda3/envs/prompt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "### 模型加载\n",
    "from modelscope import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"/home/lixinyu/weights/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"/home/lixinyu/weights/Qwen2.5-VL-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97604610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理代码\n",
    "from typing import List, Union, Dict, Any\n",
    "import torch\n",
    "from modelscope import Qwen2_5_VLForConditionalGeneration,AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "def qwen_vl_chat(\n",
    "    model: Qwen2_5_VLForConditionalGeneration,\n",
    "    processor: AutoProcessor,\n",
    "    text_query: str,\n",
    "    images: Union[str, List[str]] = None,     # 一张图或多张图\n",
    "    videos: Union[str, List[str], List[List[str]]] = None,   # 视频路径/URL 或帧列表\n",
    "    fps: float = 1.0,\n",
    "    max_pixels: int = None,   # 例如 360*420，可控制显存\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.9,\n",
    "    device: str = \"cuda\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    统一接口：图像+文字 或 视频+文字 均可\n",
    "    \"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": text_query}]\n",
    "\n",
    "    # 1) 处理图像\n",
    "    if images is not None:\n",
    "        if isinstance(images, str):\n",
    "            images = [images]\n",
    "        for img in images:\n",
    "            content.insert(0, {\"type\": \"image\", \"image\": img})\n",
    "\n",
    "    # 2) 处理视频\n",
    "    if videos is not None:\n",
    "        if isinstance(videos, str) or (isinstance(videos, list) and len(videos) and isinstance(videos[0], str)):\n",
    "            # 单个路径/URL 或 帧列表\n",
    "            content.insert(0, {\"type\": \"video\", \"video\": videos})\n",
    "        else:\n",
    "            raise ValueError(\"videos 仅支持 str 或 List[str]/List[List[str]] 格式\")\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    # 3) 构造输入\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info(\n",
    "        messages, return_video_kwargs=True\n",
    "    )\n",
    "\n",
    "    common_kwargs = {\"fps\": fps} if videos is not None else {}\n",
    "    if max_pixels is not None:\n",
    "        common_kwargs[\"max_pixels\"] = max_pixels\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        **common_kwargs,\n",
    "        **video_kwargs\n",
    "    ).to(device)\n",
    "\n",
    "    # 4) 推理\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True\n",
    "        )\n",
    "    generated_ids = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = processor.batch_decode(\n",
    "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e5f18",
   "metadata": {},
   "source": [
    "## 图像理解\n",
    "对于多模态模型，提示词的设计需要注意下面几点：\n",
    "1. 准确清楚\n",
    "2. 必要情况下，对图像进行标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dad0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"./picture/fapiao1.png\"\n",
    "text=\"请提取其中所有的信息，并按照json格式输出\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd941b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"公司名称\": \"中科视拓（南京）科技有限公司\",\n",
      "    \"税务登记号\": \"91320191MA1XM5TX71\",\n",
      "    \"发票编号\": \"24344\",\n",
      "    \"开票日期\": \"2024年01月02日\",\n",
      "    \"购买方信息\": {\n",
      "        \"名称\": \"xxxxxx限公司\",\n",
      "        \"统一社会信用代码/纳税人识别号\": \"\"\n",
      "    },\n",
      "    \"销售方信息\": {\n",
      "        \"名称\": \"中科视拓（南京）科技有限公司\",\n",
      "        \"统一社会信用代码/纳税人识别号\": \"91320191MA1XM5TX71\"\n",
      "    },\n",
      "    \"项目名称\": \"*信息技术服务*云服务器服务费\",\n",
      "    \"规格型号\": \"项\",\n",
      "    \"单位\": \"1 4716.98113207547\",\n",
      "    \"数量\": \"\",\n",
      "    \"单价\": \"4716.98\",\n",
      "    \"金额\": \"￥4716.98\",\n",
      "    \"税率/征收率\": \"6%\",\n",
      "    \"税额\": \"283.02\",\n",
      "    \"合计\": \"伍仟圆整\",\n",
      "    \"价税合计(大写)\": \"(小写)¥ 5000.00\",\n",
      "    \"备注\": \"购方开户银行:银行账号:127；\\n销方开户银行:支行;银行账号:7\",\n",
      "    \"开票人\": \"卢朦\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(qwen_vl_chat(model,processor,text_query=text,images=[image_path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa4882",
   "metadata": {},
   "source": [
    "我们也可以更精准点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d0eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"./picture/fapiao1.png\"\n",
    "text=\"请提取发票中的给出的合计的金额，并按照json格式输出\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7da813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"合计\": \"￥4716.98\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(qwen_vl_chat(model,processor,text_query=text,images=[image_path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66439033",
   "metadata": {},
   "source": [
    "我们也可以多张图分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66e713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[\"./picture/banma.jpeg\",\"./picture/xiongmao.jpeg\",\"./picture/xiaoxiongmao.jpeg\"]\n",
    "text=\"请分析三张图之间的相同点，不同点\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a999a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这三个图分别是熊猫和小熊猫的图片，还有斑马的照片，所以都是动物图片。\n",
      "不同点：熊猫主要分布在大熊猫保护区和动物园，而小熊猫也分布在熊猫的保护区，但是它们体型相差较大。斑马是生活在非洲草原的一种动物，属于马科物种。\n",
      "相同点：这三张图片都展示了动物行为和生活环境中的有趣瞬间，给观众留下深刻的印象。\n"
     ]
    }
   ],
   "source": [
    "print(qwen_vl_chat(model,processor,text_query=text,images=images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851eae0",
   "metadata": {},
   "source": [
    "如果图像中元素过多，可以对我们需要询问的对象单独框出，然后让模型理解问题，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5e1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"./picture/damoxing1.png\"\n",
    "text=\"请你解释红框中的原理\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f807472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "红框中的原理是脑科学中的“存储与检索”概念，用于描述大脑如何处理、储存和检索信息。这一过程可以分解为以下几个主要步骤：\n",
      "\n",
      "1. **获取（Grasp）**：接收到环境输入信号。\n",
      "2. **编码（Code）**：将输入以适宜的方式编码（如特征提取、模型构建等）。\n",
      "3. **储存（Store）**：将编码后的信息储存在记忆中（如长期记忆或短期记忆）。\n",
      "4. **检索（Retrieve）**：需要时从记忆中检索相关信息。\n",
      "5. **修改（Modify）**：对检索出的信息进行分析、调整。\n",
      "\n",
      "在视觉场景中，如图像识别任务，这个过程表现为神经网络识别输入图像并转换成模式表示，如神经元活跃状态图（neural activity map）、特征图（feature map），然后将其储存在记忆中，以便于后续使用。\n",
      "\n",
      "这种过程体现了智能系统的学习能力，即通过不断经历、观察（Encoding and Grasp）、处理存储数据，并根据新获得的数据进行优化（Learn, Summary, Recalling）。这些过程中蕴含了强大的学习、推理、回忆、计划等高级功能，这也是理解人工智能实现基础。\n"
     ]
    }
   ],
   "source": [
    "print(qwen_vl_chat(model,processor,text_query=text,images=[image_path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c63fd2",
   "metadata": {},
   "source": [
    "## 视频分析\n",
    "多模态模型也可以用来分析视频，不过在实际使用的时候，由于视频需要的资源都比较多，因此本地推理时显存占用一般承受不起，不过，如果资源充足，运行下面的代码即可：\n",
    "\n",
    "```python\n",
    "print(qwen_vl_chat(model,processor,text_query=text,videos=[video_path]))\n",
    "```\n",
    "\n",
    "所以本节我们使用API接口实现，我们使用阿里云百炼平台，通过调用视觉模型的API接口在本地做一个demo："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def qwen_video_chat(video_url: str, text: str,\n",
    "                    model: str = \"qwen-vl-max-latest\",\n",
    "                    max_tokens: int = 512,\n",
    "                    temperature: float = 0.7) -> str:\n",
    "    \"\"\"\n",
    "    调用阿里百炼「qwen-vl-max-latest」模型，对给定视频进行问答。\n",
    "\n",
    "    参数\n",
    "    ----\n",
    "    video_url : str\n",
    "        视频地址（http/https 或 file://）\n",
    "    text : str\n",
    "        用户想问的问题\n",
    "    model / max_tokens / temperature :\n",
    "        生成参数，可按需调整\n",
    "\n",
    "    返回\n",
    "    ----\n",
    "    answer : str\n",
    "        模型回答文本\n",
    "    \"\"\"\n",
    "    client = OpenAI(\n",
    "        api_key=\"sk-\",          # 换成自己的 Key\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"video_url\",\n",
    "                            \"video_url\": {\"url\": video_url}\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": text\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        # 捕获网络或权限异常，给出友好提示\n",
    "        return (f\"请求失败，可能原因：\\n\"\n",
    "                f\"1. 网络不通或代理设置问题；\\n\"\n",
    "                f\"2. 视频链接无效（404/403/超时）；\\n\"\n",
    "                f\"3. 密钥/计费异常。\\n\"\n",
    "                f\"建议检查链接合法性、网络连通性或稍后重试。\\n\"\n",
    "                f\"错误详情：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fda6c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241115/cqqkru/1.mp4\"\n",
    "question = \"这段视频的内容是什么？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c920935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这段视频展示了一位年轻女性的特写镜头。她有着短发，面带微笑，看起来非常开心和友好。她的穿着是一件粉色的针织开衫搭配白色的内搭，整体风格显得很清新自然。背景模糊，但可以看出是在户外，可能是一个校园或公园等地方。视频中的女性表情生动，笑容灿烂，给人一种温暖和愉快的感觉。右上角有“通义·AI合成”的字样，表明这段视频可能是通过AI技术合成的。\n"
     ]
    }
   ],
   "source": [
    "print(qwen_video_chat(video, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb73e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
